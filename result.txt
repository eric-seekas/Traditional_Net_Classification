************************1.BiLSTM_Att************************
参数：
batch-size：32
learning-rate：5e-3
pad-size：160
hidden_size = 256
结果:
Test Loss: 0.042,  Test Acc: 98.29%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

    negative     0.9691    0.9973    0.9830      5952
    positive     0.9973    0.9687    0.9828      6047

    accuracy                         0.9829     11999
   macro avg     0.9832    0.9830    0.9829     11999
weighted avg     0.9833    0.9829    0.9829     11999

Confusion Matrix...
[[5936   16]
 [ 189 5858]]
Time usage: 0:00:02



************************2.FastText************************
batch-size：32
learning-rate：1e-3
pad-size：160
hidden_size = 256
结果:
Test Loss: 0.063,  Test Acc: 97.65%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

    negative     0.9660    0.9874    0.9766      5952
    positive     0.9873    0.9658    0.9764      6047

    accuracy                         0.9765     11999
   macro avg     0.9766    0.9766    0.9765     11999
weighted avg     0.9767    0.9765    0.9765     11999

Confusion Matrix...
[[5877   75]
 [ 207 5840]]
Time usage: 0:00:00


************************3.TextRCNN************************
batch-size：32
learning-rate：1e-3
pad-size：160
hidden_size = 256
结果:
Test Loss: 0.067,  Test Acc: 97.59%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

    negative     0.9597    0.9931    0.9761      5952
    positive     0.9930    0.9590    0.9757      6047

    accuracy                         0.9759     11999
   macro avg     0.9764    0.9760    0.9759     11999
weighted avg     0.9765    0.9759    0.9759     11999

Confusion Matrix...
[[5911   41]
 [ 248 5799]]
Time usage: 0:00:03

